{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "areas = [6.7, 4.6, 3.5, 5.5]\n",
    "prices = [9.1, 5.9, 4.6, 6.7]\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'areas' : areas,\n",
    "    'prices' : prices\n",
    "})\n",
    "\n",
    "### Cài đặt mô hình Linear Regression\n",
    "#forward\n",
    "def predict(x, w, b):\n",
    "    return x*w + b\n",
    "\n",
    "#compute gradient\n",
    "def gradient(y_hat, y, x):\n",
    "    dw = 2*x*(y_hat - y)\n",
    "    db = 2*(y_hat - y)\n",
    "    return (dw, db)\n",
    "\n",
    "#update weights\n",
    "def update_weight(w, b, lr, dw, db):\n",
    "    w_new = w - lr*dw\n",
    "    b_new = b - lr*db\n",
    "    return (w_new, b_new)\n",
    "\n",
    "### Huấn luyện\n",
    "# init weights\n",
    "b = 0.04\n",
    "w = -0.34\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "\n",
    "#init project wandb\n",
    "wandb.init(\n",
    "    #Set the project where this run will be logged\n",
    "    project=\"demo-linear-regression\",\n",
    "    config={\n",
    "        \"learning_rate\" : lr,\n",
    "        \"epochs\" : epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "wandb.run.log({\"Dataset\" : wandb.Table(dataframe=dataset)})\n",
    "\n",
    "X_train = dataset['areas']\n",
    "Y_train = dataset['prices']\n",
    "N = len(X_train)\n",
    "\n",
    "#parameter\n",
    "losses = [] # for debug\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #for an epoch\n",
    "    for i in range(N):\n",
    "        #get the sample\n",
    "        x = X_train[i]\n",
    "        y = Y_train[i]\n",
    "\n",
    "        #predict y_hat\n",
    "        y_hat = predict(x, w, b)\n",
    "\n",
    "        #compute loss\n",
    "        loss = ((y_hat - y)**2) / 2.0\n",
    "\n",
    "        # tracking loss with wandb\n",
    "        wandb.log({\"loss\" : loss})\n",
    "\n",
    "        # compute gradient\n",
    "        (dw, db) = gradient(y_hat, y, x)\n",
    "\n",
    "        # update weights\n",
    "        (w, b) = update_weight(w, b, lr, dw, db)\n",
    "\n",
    "# Mark a run as finished, and finish uploading all data\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "data_advertising = pd.read_csv('advertising.csv')\n",
    "\n",
    "X_data = data_advertising.drop([\"Sales\"], axis=1)\n",
    "Y_data = data_advertising[\"Sales\"]\n",
    "\n",
    "# compute output and loss\n",
    "def predict(x1, x2, x3, w1, w2, w3, b):\n",
    "    return x1*w1 + x2*w2 + x3*w3 + b\n",
    "\n",
    "def compute_loss(y_hat, y):\n",
    "    return ((y_hat - y)**2) / 2.0\n",
    "\n",
    "# compute gradient\n",
    "def compute_gradient_wi(xi, y, y_hat):\n",
    "    dl_dwi = 2*xi*(y_hat - y)\n",
    "    return dl_dwi\n",
    "\n",
    "def compute_gradient_b(y, y_hat):\n",
    "    dl_db = 2*(y_hat - y)\n",
    "    return dl_db\n",
    "\n",
    "# update weight\n",
    "def update_weight_wi(wi, dwi, lr):\n",
    "    new_wi = wi - lr * dwi\n",
    "    return new_wi\n",
    "\n",
    "def update_weight_b(b, db, lr):\n",
    "    new_b = b - lr * db\n",
    "    return new_b\n",
    "\n",
    "print(Y_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Huấn luyện\n",
    "# init weights\n",
    "b = 1\n",
    "w1, w2, w3 = 0, 0, 0\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "#init project wandb\n",
    "wandb.init(\n",
    "    #Set the project where this run will be logged\n",
    "    project=\"demo-linear-regression-advertisingData\",\n",
    "    config={\n",
    "        \"learning_rate\" : lr,\n",
    "        \"epochs\" : epochs,\n",
    "    },\n",
    ")\n",
    "\n",
    "wandb.run.log({\"Dataset\" : wandb.Table(dataframe=dataset)})\n",
    "\n",
    "N = len(Y_data)\n",
    "\n",
    "#parameter\n",
    "losses = [] # for debug\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #for an epoch\n",
    "    for i in range(N):\n",
    "        #get the sample\n",
    "        x1 = X_data['TV'][i]\n",
    "        x2 = X_data['Radio'][i]\n",
    "        x3 = X_data['Newspaper'][i]\n",
    "        y = Y_data[i]\n",
    "\n",
    "        #predict y_hat\n",
    "        y_hat = predict(x1, x2, x3, w1, w2, w3, b)\n",
    "\n",
    "        #compute loss\n",
    "        loss = compute_loss(y_hat, y)\n",
    "\n",
    "        # tracking loss with wandb\n",
    "        wandb.log({\"loss\" : loss})\n",
    "\n",
    "        # compute gradient w1, w2, w3, b\n",
    "        dl_dw1 = compute_gradient_wi(x1, y, y_hat)\n",
    "        dl_dw2 = compute_gradient_wi(x2, y, y_hat)\n",
    "        dl_dw3 = compute_gradient_wi(x3, y, y_hat)\n",
    "        dl_db  = compute_gradient_b(y, y_hat)\n",
    "\n",
    "        # update parameters\n",
    "        w1 = update_weight_wi(w1, dl_dw1, lr)\n",
    "        w2 = update_weight_wi(w2, dl_dw2, lr)\n",
    "        w3 = update_weight_wi(w3, dl_dw3, lr)\n",
    "        b  = update_weight_b(b, dl_db, lr)\n",
    "\n",
    "# Mark a run as finished, and finish uploading all data\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
